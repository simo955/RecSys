{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "from SLIM_ElasticNet.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "\n",
    "from MatrixFactorization.Cython.MatrixFactorization_Cython import MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython\n",
    "from MatrixFactorization.PureSVD import PureSVDRecommender\n",
    "\n",
    "from Base.NonPersonalizedRecommender import TopPop, Random\n",
    "\n",
    "from KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender\n",
    "\n",
    "from KNN.ItemKNNScoresHybridRecommender import ItemKNNScoresHybridRecommender\n",
    "from KNN.ItemKNNScoresHybridRecommender3 import ItemKNNScoresHybridRecommender3\n",
    "\n",
    "from KNN.ItemKNNSimilarityHybridRecommender import ItemKNNSimilarityHybridRecommender\n",
    "from KNN.ItemKNNSimilarityHybridRecommender3 import ItemKNNSimilarityHybridRecommender3\n",
    "from KNN.ItemKNNSimilarityHybridRecommender4 import ItemKNNSimilarityHybridRecommender4\n",
    "\n",
    "from KNN.UserKNNCBF1Recommender import UserKNNCBF1Recommender\n",
    "from KNN.UserKNNCBFRecommender import UserKNNCBFRecommender\n",
    "\n",
    "\n",
    "#from GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "#from GraphBased.P3alphaRecommender import P3alphaRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, os\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "URM_all = scipy.sparse.load_npz('./Matrix/URM_all_matrix.npz')\n",
    "ICM_all = scipy.sparse.load_npz('./Matrix/ICM_all_matrix.npz')\n",
    "URM_train = scipy.sparse.load_npz('./Matrix/URM_train_matrix.npz')\n",
    "URM_test = scipy.sparse.load_npz('./Matrix/URM_test_matrix.npz')\n",
    "UCM_all = scipy.sparse.load_npz('./Matrix/UCM_all_matrix.npz')\n",
    "UCM_train = scipy.sparse.load_npz('UCM_train_matrix1.npz')\n",
    "\n",
    "\n",
    "\n",
    "#Load playlistsIDS\n",
    "train_df= pd.read_csv('all/train.csv',low_memory = False)\n",
    "all_userID=train_df.playlist_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_sparse = URM_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    " \n",
    "    \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i) vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "     \"\"\"\n",
    "\n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = sparse_data * alpha_val\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "    #Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "    \n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base.NonPersonalizedRecommender import TopPop, Random\n",
    "from KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from SLIM_BPR.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "from SLIM_ElasticNet.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from MatrixFactorization.Cython.MatrixFactorization_Cython import MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython\n",
    "from MatrixFactorization.PureSVD import PureSVDRecommender\n",
    "\n",
    "from ParameterTuning.BayesianSearch import BayesianSearch\n",
    "\n",
    "\n",
    "import traceback, pickle\n",
    "from Utils.PoolWithSubprocess import PoolWithSubprocess\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ParameterTuning.AbstractClassSearch import DictionaryKeys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 22/11/17\n",
    "\n",
    "@author: Maurizio Ferrari Dacrema\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def run_KNNCFRecommender_on_similarity_type(similarity_type, parameterSearch, URM_train, n_cases, output_root_path, metric_to_optimize):\n",
    "\n",
    "    hyperparamethers_range_dictionary = {}\n",
    "    hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "    hyperparamethers_range_dictionary[\"shrink\"] = [0, 10, 50, 100, 200, 300, 500, 1000]\n",
    "    hyperparamethers_range_dictionary[\"similarity\"] = [similarity_type]\n",
    "    hyperparamethers_range_dictionary[\"normalize\"] = [True, False]\n",
    "\n",
    "    if similarity_type == \"asymmetric\":\n",
    "        hyperparamethers_range_dictionary[\"asymmetric_alpha\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"normalize\"] = [True]\n",
    "\n",
    "    elif similarity_type == \"tversky\":\n",
    "        hyperparamethers_range_dictionary[\"tversky_alpha\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"tversky_beta\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"normalize\"] = [True]\n",
    "\n",
    "\n",
    "    recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                             DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                             DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                             DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                             DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "    output_root_path_similarity = output_root_path + \"_\" + similarity_type\n",
    "\n",
    "    best_parameters = parameterSearch.search(recommenderDictionary,\n",
    "                                             n_cases = n_cases,\n",
    "                                             output_root_path = output_root_path_similarity,\n",
    "                                             metric=metric_to_optimize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_KNNCBFRecommender_on_similarity_type(similarity_type, parameterSearch, URM_train, ICM_train, n_cases, output_root_path, metric_to_optimize):\n",
    "\n",
    "    hyperparamethers_range_dictionary = {}\n",
    "    hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "    hyperparamethers_range_dictionary[\"shrink\"] = [0, 10, 50, 100, 200, 300, 500, 1000]\n",
    "    hyperparamethers_range_dictionary[\"similarity\"] = [similarity_type]\n",
    "    hyperparamethers_range_dictionary[\"normalize\"] = [True, False]\n",
    "\n",
    "    if similarity_type == \"asymmetric\":\n",
    "        hyperparamethers_range_dictionary[\"asymmetric_alpha\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"normalize\"] = [True]\n",
    "\n",
    "    elif similarity_type == \"tversky\":\n",
    "        hyperparamethers_range_dictionary[\"tversky_alpha\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"tversky_beta\"] = range(0, 2)\n",
    "        hyperparamethers_range_dictionary[\"normalize\"] = [True]\n",
    "\n",
    "    if similarity_type in [\"cosine\", \"asymmetric\"]:\n",
    "        hyperparamethers_range_dictionary[\"feature_weighting\"] = [\"none\", \"BM25\", \"TF-IDF\"]\n",
    "\n",
    "\n",
    "\n",
    "    recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [ICM_train, URM_train],\n",
    "                             DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                             DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                             DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                             DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "    output_root_path_similarity = output_root_path + \"_\" + similarity_type\n",
    "\n",
    "    best_parameters = parameterSearch.search(recommenderDictionary,\n",
    "                                             n_cases = n_cases,\n",
    "                                             output_root_path = output_root_path_similarity,\n",
    "                                             metric=metric_to_optimize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def runParameterSearch_Content(recommender_class, URM_train, ICM_object, ICM_name, n_cases = 30,\n",
    "                             evaluator_validation= None, evaluator_test=None, metric_to_optimize = \"PRECISION\",\n",
    "                             output_root_path =\"result_experiments/\", parallelizeKNN = False):\n",
    "\n",
    "\n",
    "    # If directory does not exist, create\n",
    "    if not os.path.exists(output_root_path):\n",
    "        os.makedirs(output_root_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   ##########################################################################################################\n",
    "\n",
    "    this_output_root_path = output_root_path + recommender_class.RECOMMENDER_NAME + \"_{}\".format(ICM_name)\n",
    "\n",
    "    parameterSearch = BayesianSearch(recommender_class, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test)\n",
    "\n",
    "\n",
    "    similarity_type_list = ['cosine', 'jaccard', \"asymmetric\", \"dice\", \"tversky\"]\n",
    "\n",
    "    run_KNNCBFRecommender_on_similarity_type_partial = partial(run_KNNCBFRecommender_on_similarity_type,\n",
    "                                                   parameterSearch = parameterSearch,\n",
    "                                                   URM_train = URM_train,\n",
    "                                                   ICM_train = ICM_object,\n",
    "                                                   n_cases = n_cases,\n",
    "                                                   output_root_path = this_output_root_path,\n",
    "                                                   metric_to_optimize = metric_to_optimize)\n",
    "\n",
    "\n",
    "\n",
    "    if parallelizeKNN:\n",
    "        pool = PoolWithSubprocess(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n",
    "        resultList = pool.map(run_KNNCBFRecommender_on_similarity_type_partial, similarity_type_list)\n",
    "\n",
    "    else:\n",
    "\n",
    "        for similarity_type in similarity_type_list:\n",
    "            run_KNNCBFRecommender_on_similarity_type_partial(similarity_type)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def runParameterSearch_Collaborative(recommender_class, URM_train, metric_to_optimize = \"PRECISION\",\n",
    "                                     evaluator_validation= None, evaluator_test=None, evaluator_validation_earlystopping = None,\n",
    "                                     output_root_path =\"result_experiments/\", parallelizeKNN = True, n_cases = 30):\n",
    "\n",
    "\n",
    "    from ParameterTuning.AbstractClassSearch import DictionaryKeys\n",
    "\n",
    "\n",
    "    # If directory does not exist, create\n",
    "    if not os.path.exists(output_root_path):\n",
    "        os.makedirs(output_root_path)\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        output_root_path_rec_name = output_root_path + recommender_class.RECOMMENDER_NAME\n",
    "\n",
    "        parameterSearch = BayesianSearch(recommender_class, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if recommender_class in [TopPop, Random]:\n",
    "\n",
    "            recommender = recommender_class(URM_train)\n",
    "\n",
    "            recommender.fit()\n",
    "\n",
    "            output_file = open(output_root_path_rec_name + \"_BayesianSearch.txt\", \"a\")\n",
    "            result_dict, result_baseline = evaluator_validation.evaluateRecommender(recommender)\n",
    "            output_file.write(\"ParameterSearch: Best result evaluated on URM_validation. Results: {}\".format(result_baseline))\n",
    "\n",
    "            pickle.dump(result_dict.copy(),\n",
    "                        open(output_root_path_rec_name + \"_best_result_validation\", \"wb\"),\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            result_dict, result_baseline = evaluator_test.evaluateRecommender(recommender)\n",
    "            output_file.write(\"ParameterSearch: Best result evaluated on URM_test. Results: {}\".format(result_baseline))\n",
    "\n",
    "            pickle.dump(result_dict.copy(),\n",
    "                        open(output_root_path_rec_name + \"_best_result_test\", \"wb\"),\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "            output_file.close()\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is UserKNNCFRecommender:\n",
    "\n",
    "            similarity_type_list = ['cosine', 'jaccard', \"asymmetric\", \"dice\", \"tversky\"]\n",
    "\n",
    "            run_KNNCFRecommender_on_similarity_type_partial = partial(run_KNNCFRecommender_on_similarity_type,\n",
    "                                                           parameterSearch = parameterSearch,\n",
    "                                                           URM_train = URM_train,\n",
    "                                                           n_cases = n_cases,\n",
    "                                                           output_root_path = output_root_path_rec_name,\n",
    "                                                           metric_to_optimize = metric_to_optimize)\n",
    "\n",
    "\n",
    "\n",
    "            if parallelizeKNN:\n",
    "                pool = PoolWithSubprocess(processes=int(2), maxtasksperchild=1)\n",
    "                resultList = pool.map(run_KNNCFRecommender_on_similarity_type_partial, similarity_type_list)\n",
    "\n",
    "            else:\n",
    "\n",
    "                for similarity_type in similarity_type_list:\n",
    "                    run_KNNCFRecommender_on_similarity_type_partial(similarity_type)\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is ItemKNNCFRecommender:\n",
    "\n",
    "            similarity_type_list = ['cosine', 'jaccard', \"asymmetric\", \"dice\", \"tversky\"]\n",
    "\n",
    "            run_KNNCFRecommender_on_similarity_type_partial = partial(run_KNNCFRecommender_on_similarity_type,\n",
    "                                                           parameterSearch = parameterSearch,\n",
    "                                                           URM_train = URM_train,\n",
    "                                                           n_cases = n_cases,\n",
    "                                                           output_root_path = output_root_path_rec_name,\n",
    "                                                           metric_to_optimize = metric_to_optimize)\n",
    "\n",
    "\n",
    "            if parallelizeKNN:\n",
    "                pool = PoolWithSubprocess(processes=int(2), maxtasksperchild=1)\n",
    "                resultList = pool.map(run_KNNCFRecommender_on_similarity_type_partial, similarity_type_list)\n",
    "\n",
    "            else:\n",
    "\n",
    "                for similarity_type in similarity_type_list:\n",
    "                    run_KNNCFRecommender_on_similarity_type_partial(similarity_type)\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        # if recommender_class is MultiThreadSLIM_RMSE:\n",
    "        #\n",
    "        #     hyperparamethers_range_dictionary = {}\n",
    "        #     hyperparamethers_range_dictionary[\"topK\"] = [50, 100]\n",
    "        #     hyperparamethers_range_dictionary[\"l1_penalty\"] = [1e-2, 1e-3, 1e-4]\n",
    "        #     hyperparamethers_range_dictionary[\"l2_penalty\"] = [1e-2, 1e-3, 1e-4]\n",
    "        #\n",
    "        #\n",
    "        #     recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "        #                              DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "        #                              DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "        #                              DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "        #                              DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "        #\n",
    "        #\n",
    "\n",
    "\n",
    "       ##########################################################################################################\n",
    "\n",
    "        if recommender_class is P3alphaRecommender:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "            hyperparamethers_range_dictionary[\"alpha\"] = range(0, 2)\n",
    "            hyperparamethers_range_dictionary[\"normalize_similarity\"] = [True, False]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is RP3betaRecommender:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"topK\"] = [5, 10, 20, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800]\n",
    "            hyperparamethers_range_dictionary[\"alpha\"] = range(0, 2)\n",
    "            hyperparamethers_range_dictionary[\"beta\"] = range(0, 2)\n",
    "            hyperparamethers_range_dictionary[\"normalize_similarity\"] = [True, False]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is MatrixFactorization_FunkSVD_Cython:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"sgd_mode\"] = [\"adagrad\", \"adam\"]\n",
    "            #hyperparamethers_range_dictionary[\"epochs\"] = [1, 5, 10, 20, 30, 50, 70, 90, 110]\n",
    "            hyperparamethers_range_dictionary[\"num_factors\"] = [1, 5, 10, 20, 30, 50, 70, 90, 110]\n",
    "            hyperparamethers_range_dictionary[\"reg\"] = [0.0, 1e-3, 1e-6, 1e-9]\n",
    "            hyperparamethers_range_dictionary[\"learning_rate\"] = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: {\"validation_every_n\":5, \"stop_on_validation\":True,\n",
    "                                                                       \"evaluator_object\":evaluator_validation_earlystopping,\n",
    "                                                                       \"lower_validatons_allowed\":20, \"validation_metric\":metric_to_optimize},\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is MatrixFactorization_BPR_Cython:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"sgd_mode\"] = [\"adagrad\", \"adam\"]\n",
    "            #hyperparamethers_range_dictionary[\"epochs\"] = [1, 5, 10, 20, 30, 50, 70, 90, 110]\n",
    "            hyperparamethers_range_dictionary[\"num_factors\"] = [1, 5, 10, 20, 30, 50, 70, 90, 110]\n",
    "            hyperparamethers_range_dictionary[\"batch_size\"] = [1]\n",
    "            hyperparamethers_range_dictionary[\"positive_reg\"] = [0.0, 1e-3, 1e-6, 1e-9]\n",
    "            hyperparamethers_range_dictionary[\"negative_reg\"] = [0.0, 1e-3, 1e-6, 1e-9]\n",
    "            hyperparamethers_range_dictionary[\"learning_rate\"] = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {'positive_threshold':0},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: {\"validation_every_n\":5, \"stop_on_validation\":True,\n",
    "                                                                       \"evaluator_object\":evaluator_validation_earlystopping,\n",
    "                                                                       \"lower_validatons_allowed\":20, \"validation_metric\":metric_to_optimize},\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is PureSVDRecommender:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"num_factors\"] = list(range(0, 250, 5))\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "        #########################################################################################################\n",
    "\n",
    "        if recommender_class is SLIM_BPR_Cython:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"topK\"] = [10, 50, 100, 200, 500, 800]\n",
    "            hyperparamethers_range_dictionary[\"epochs\"] = [5,10, 30, 50, 70, 110]\n",
    "            hyperparamethers_range_dictionary[\"sgd_mode\"] = [\"adagrad\", \"adam\"]\n",
    "            hyperparamethers_range_dictionary[\"lambda_i\"] = [0.0, 1e-2,1e-3, 1e-6, 1e-9]\n",
    "            hyperparamethers_range_dictionary[\"lambda_j\"] = [0.0, 1e-2,1e-3, 1e-6, 1e-9]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {'train_with_sparse_weights':True, 'symmetric':True, 'positive_threshold':0},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: {\"validation_every_n\":5, \"stop_on_validation\":True,\n",
    "                                                                       \"evaluator_object\":evaluator_validation_earlystopping,\n",
    "                                                                       \"lower_validatons_allowed\":10, \"validation_metric\":metric_to_optimize},\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################################\n",
    "\n",
    "        if recommender_class is SLIMElasticNetRecommender:\n",
    "\n",
    "            hyperparamethers_range_dictionary = {}\n",
    "            hyperparamethers_range_dictionary[\"alpha\"] = [1, 0.01, 0.001,0.0001]\n",
    "            hyperparamethers_range_dictionary[\"topK\"] = [10, 100, 200, 500, 800]\n",
    "            hyperparamethers_range_dictionary[\"l1_ratio\"] = [1.0, 0.0, 0.1, 0.5, 0.05, 1e-2, 1e-4]\n",
    "\n",
    "            recommenderDictionary = {DictionaryKeys.CONSTRUCTOR_POSITIONAL_ARGS: [URM_train],\n",
    "                                     DictionaryKeys.CONSTRUCTOR_KEYWORD_ARGS: {},\n",
    "                                     DictionaryKeys.FIT_POSITIONAL_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_KEYWORD_ARGS: dict(),\n",
    "                                     DictionaryKeys.FIT_RANGE_KEYWORD_ARGS: hyperparamethers_range_dictionary}\n",
    "\n",
    "\n",
    "\n",
    "       #########################################################################################################\n",
    "\n",
    "        ## Final step, after the hyperparameter range has been defined for each type of algorithm\n",
    "        best_parameters = parameterSearch.search(recommenderDictionary,\n",
    "                                                 n_cases = n_cases,\n",
    "                                                 output_root_path = output_root_path_rec_name,\n",
    "                                                 metric = metric_to_optimize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"On recommender {} Exception {}\".format(recommender_class, str(e)))\n",
    "        traceback.print_exc()\n",
    "\n",
    "        error_file = open(output_root_path + \"ErrorLog.txt\", \"a\")\n",
    "        error_file.write(\"On recommender {} Exception {}\\n\".format(recommender_class, str(e)))\n",
    "        error_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   l1_ratio |      topK | \n",
      "BayesianSearch: Testing config: {'alpha': 1, 'topK': 200, 'l1_ratio': 0.01}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7359dd110956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mread_data_split_and_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7359dd110956>\u001b[0m in \u001b[0;36mread_data_split_and_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mrunParameterSearch_Collaborative_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-621e551f3b78>\u001b[0m in \u001b[0;36mrunParameterSearch_Collaborative\u001b[0;34m(recommender_class, URM_train, metric_to_optimize, evaluator_validation, evaluator_test, evaluator_validation_earlystopping, output_root_path, parallelizeKNN, n_cases)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                                  \u001b[0mn_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                                                  \u001b[0moutput_root_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_root_path_rec_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                                                  metric = metric_to_optimize)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianSearch.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, dictionary, metric, init_points, n_cases, output_root_path, parallelPoolSize, parallelize, save_model)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesian_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mbest_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesian_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianOptimization_master/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianOptimization_master/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, init_points)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Evaluate target function at all initialization points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observe_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Add the points from `self.initialize` to the observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianOptimization_master/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m_observe_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_observe_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianOptimization_master/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mobserve_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# measure the target function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianSearch.py\u001b[0m in \u001b[0;36mrunSingleCase\u001b[0;34m(self, dictionary, metric, **paramether_dictionary_input)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mparamether_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_bayesian_to_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamether_dictionary_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunSingleCase_param_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamether_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/ParameterTuning/BayesianSearch.py\u001b[0m in \u001b[0;36mrunSingleCase_param_parsed\u001b[0;34m(self, dictionary, metric, paramether_dictionary)\u001b[0m\n\u001b[1;32m    227\u001b[0m             recommender.fit(*dictionary[DictionaryKeys.FIT_POSITIONAL_ARGS],\n\u001b[1;32m    228\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDictionaryKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIT_KEYWORD_ARGS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                             **paramether_dictionary)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m#return recommender.evaluateRecommendations(self.URM_validation, at=5, mode=\"sequential\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/newRecSysExam/SLIM_ElasticNet/SLIMElasticNetRecommender.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, alpha, topK, l1_ratio, positive_only)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# fit one ElasticNet model per column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# self.model.coef_ contains the coefficient of the ElasticNet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    759\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sparse_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                 max_iter, tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os, multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_data_split_and_search():\n",
    "    \"\"\"\n",
    "    This function pr\n",
    "    ovides a simple example on how to tune parameters of a given algorithm\n",
    "\n",
    "    The BayesianSearch object will save:\n",
    "        - A .txt file with all the cases explored and the recommendation quality\n",
    "        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\n",
    "        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\n",
    "        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\n",
    "        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    import traceback, os\n",
    "    import scipy.sparse\n",
    "    URM_all = scipy.sparse.load_npz('./Matrix/URM_all_matrix.npz')\n",
    "    ICM_all = scipy.sparse.load_npz('./Matrix/ICM_all_matrix.npz')\n",
    "    URM_train = scipy.sparse.load_npz('./Matrix/URM_train_matrix.npz')\n",
    "    URM_test = scipy.sparse.load_npz('./Matrix/URM_test_matrix.npz')\n",
    "\n",
    "    \n",
    "\n",
    "    output_root_path = \"result_experiments/\"\n",
    "\n",
    "\n",
    "    # If directory does not exist, create\n",
    "    if not os.path.exists(output_root_path):\n",
    "        os.makedirs(output_root_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    collaborative_algorithm_list = [\n",
    "       #SLIM_BPR_Cython,\n",
    "        #TopPop,\n",
    "        #P3alphaRecommender,\n",
    "        #RP3betaRecommender,\n",
    "        #ItemKNNCFRecommender,\n",
    "        #UserKNNCFRecommender,\n",
    "        #MatrixFactorization_BPR_Cython,\n",
    "        #MatrixFactorization_FunkSVD_Cython,\n",
    "        #PureSVDRecommender,\n",
    "        SLIMElasticNetRecommender\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from ParameterTuning.AbstractClassSearch import EvaluatorWrapper\n",
    "    from Base.Evaluation.Evaluator import SequentialEvaluator\n",
    "\n",
    "    evaluator_validation_earlystopping = SequentialEvaluator(URM_test, cutoff_list=[10])\n",
    "    evaluator_test = SequentialEvaluator(URM_test, cutoff_list=[10])\n",
    "\n",
    "\n",
    "    evaluator_validation = EvaluatorWrapper(evaluator_validation_earlystopping)\n",
    "    evaluator_test = EvaluatorWrapper(evaluator_test)\n",
    "\n",
    "\n",
    "\n",
    "    runParameterSearch_Collaborative_partial = partial(runParameterSearch_Collaborative,\n",
    "                                                       URM_train = URM_train,\n",
    "                                                       metric_to_optimize = \"MAP\",\n",
    "                                                       evaluator_validation_earlystopping = evaluator_validation_earlystopping,\n",
    "                                                       evaluator_validation = evaluator_validation,\n",
    "                                                       evaluator_test = evaluator_test,\n",
    "                                                       output_root_path=output_root_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n",
    "    # resultList = pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n",
    "\n",
    "\n",
    "\n",
    "    for recommender_class in collaborative_algorithm_list:\n",
    "\n",
    "        try:\n",
    "\n",
    "            runParameterSearch_Collaborative_partial(recommender_class)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"On recommender {} Exception {}\".format(recommender_class, str(e)))\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    read_data_split_and_search()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
